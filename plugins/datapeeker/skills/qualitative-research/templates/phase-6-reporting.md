# Findings Report

**Session:** [session-name]
**Date:** [YYYY-MM-DD]
**Phase:** 6 - Synthesis & Reporting

---

## Research Overview

**Research Question:** [From Phase 1]

**Method:** [Interview / Survey / Focus Group / Observation]

**Sample:**
- Total participants: [N]
- Data collection period: [Date range]
- Saturation achieved: [Yes / No / Partial]

**Analysis Approach:**
- Coding method: Thematic Analysis
- Codebook: [N] codes developed
- Themes identified: [N] themes
- Intercoder reliability: [X]% agreement (Kappa [X.XX])

---

## Main Findings

### Theme 1: [Theme Name]

**Definition:** [Theme definition from Phase 5]

**Prevalence:** [X of Y participants] ([Z]%)

**Representative Quotes:**

> "[Quote 1]" - Participant [N]

> "[Quote 2]" - Participant [N]

> "[Quote 3]" - Participant [N]

**Negative Cases:** [A] of [Y] participants did not exhibit this theme.
- These participants [explanation of what they showed instead]

**Context:** [When/where does this theme apply? What conditions are present?]

---

### Theme 2: [Theme Name]

[Same structure as Theme 1...]

---

### Theme 3: [Theme Name]

[Same structure as Theme 1...]

---

## Cross-Theme Patterns

**Relationships between themes:**

**Themes 1 & 2:** [How they relate - complementary, sequential, conditional?]

**Themes 2 & 3:** [Relationship]

**Dominant pattern:** [Which theme was most prevalent? What does this mean?]

---

## Limitations (MANDATORY - Be HONEST)

**Purpose:** Acknowledge constraints and uncertainties to strengthen credibility.

### Sample Limitations

**Size:** [N] participants
- Impact: [How does sample size limit generalizability?]
- Adequacy for saturation: [Was saturation achieved? If not, what's missing?]

**Homogeneity/Diversity:**
- [Describe sample composition]
- [What perspectives might be missing?]
- [How does this limit transferability?]

**Recruitment:**
- Method: [How were participants recruited?]
- Potential bias: [Does recruitment method introduce selection bias?]

### Method Constraints

**Data collection:**
- [Interviews: Single conversation vs. longitudinal?]
- [Surveys: Response rate? Self-report limitations?]
- [Focus groups: Group dynamics influence?]
- [Observations: Observer effect?]

**Analysis:**
- Single primary coder (intercoder reliability check: [X]%)
- Coding decisions subject to interpretation despite systematic approach
- Themes emerged from this specific dataset

### Researcher Bias

**From Phase 1 reflexivity baseline:**
- Assumption 1: [How this may have influenced interpretation]
- Assumption 2: [Impact on question design or analysis]

**Mitigation:**
- Disconfirming evidence search for all themes
- Intercoder reliability check
- Negative cases documented and explained

### Context Limitations

**Geography:** [Where was this research conducted? How does location limit generalizability?]

**Time period:** [When? Are findings time-dependent?]

**Industry/domain:** [Specific to certain context?]

**Conditions:** [What conditions were present that might not apply elsewhere?]

---

## Confidence Assessment

**Purpose:** Evaluate trustworthiness of findings using qualitative rigor criteria.

### Credibility (Internal Validity)
**Question:** Do findings accurately represent participant experiences?

**Assessment:** [High / Medium / Low]

**Justification:**
- [Evidence: prolonged engagement, member checking, triangulation, etc.]
- [Strengths that support credibility]
- [Weaknesses that undermine credibility]

### Dependability (Reliability)
**Question:** Would another researcher reach similar conclusions?

**Assessment:** [High / Medium / Low]

**Justification:**
- Intercoder reliability: [X]% agreement
- Detailed audit trail: [Complete documentation of decisions]
- [Other evidence of consistency]

### Confirmability (Objectivity)
**Question:** Are findings based on data, not researcher bias?

**Assessment:** [High / Medium / Low]

**Justification:**
- Disconfirming evidence search completed for all themes
- Negative cases documented
- Reflexivity maintained throughout
- [Evidence that findings grounded in data]

### Transferability (External Validity)
**Question:** Do findings apply beyond this specific sample?

**Assessment:** [High / Medium / Low]

**Justification:**
- Thick description provided: [Context, participants, conditions]
- [Evidence supporting broader applicability]
- [Limitations to transferability noted above]

---

## Follow-Up Research Questions

**Purpose:** Every analysis should raise new questions.

### Question 1: [What would you investigate next?]

**Why this matters:** [How does this extend/deepen current findings?]

**Approach:** [How would you investigate this? What method? What sample?]

**Expected contribution:** [What would answering this add to understanding?]

---

### Question 2: [What surprised you that needs deeper exploration?]

**Why this matters:**

**Approach:**

**Expected contribution:**

---

### Question 3: [What would strengthen confidence in current findings?]

**Why this matters:**

**Approach:**

**Expected contribution:**

---

## Signal Classification (if invoked by marketing-experimentation)

**Hypothesis tested:** [From marketing-experimentation experiment tracker]

**Expected outcome:** [What was predicted?]

**Actual outcome:** [What did the data show?]

**Signal:** [POSITIVE / NEGATIVE / NULL / MIXED]

**Justification:**
[Based on themes and prevalence, how does this validate or invalidate the hypothesis?]

**Confidence in signal:** [High / Medium / Low]

**Recommendation:**
[Based on this signal, what should happen next in the marketing-experimentation cycle?]

---

## Summary

**In 3-5 bullet points, what are the key takeaways?**

- [Finding 1 with prevalence]
- [Finding 2 with prevalence]
- [Finding 3 with prevalence]
- [Notable negative case or limitation]
- [Strongest follow-up question]

**Confidence level:** [Overall assessment: High / Medium / Low]

**Most important insight:** [What's the single most important thing we learned?]

---

## Phase 6 Checkpoint Verification

**Before marking complete, verify:**

- [ ] All themes documented with representative quotes
- [ ] Prevalence reported honestly (X of Y, not "all" or "most")
- [ ] Negative cases explained for each theme
- [ ] **Limitations explicitly stated** (sample, method, researcher bias, context)
- [ ] Confidence assessment completed (credibility, dependability, confirmability, transferability)
- [ ] 2-3 follow-up research questions identified
- [ ] Signal classification provided (if for marketing-experimentation)
- [ ] Summary section completed
- [ ] All results saved to `06-findings-report.md`
- [ ] `00-overview.md` updated with final summary

**Checkpoint status:** [PASS / FAIL]

**If PASS:** Analysis complete. Overview updated. Git commit ready.
**If FAIL:** Complete missing requirements above
